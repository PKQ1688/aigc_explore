#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# @File    :   label_tool.py
# @Time    :   2023/02/07 10:54:08
# @Author  :   Adolf 
# @Desc    :   None
import torch
import random
import pandas as pd
import streamlit as st
from itertools import combinations
from transformers import T5Tokenizer, T5ForConditionalGeneration

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

st.set_page_config(
    page_title="Rank Labeler Tool",
    page_icon='ğŸ–ï¸',
    layout="wide"
)

MODEL_CONFIG = {
    'model_name': 'uer/gpt2-chinese-cluecorpussmall',  # backbone
    'device': 'cuda:0',  # ä½¿ç”¨è®¾å¤‡
    'dataset_file': 'data/human_labeled/total_dataset.tsv',  # æ ‡æ³¨æ•°æ®é›†çš„å­˜æ”¾æ–‡ä»¶
    'rank_list_len': 4,  # æ’åºåˆ—è¡¨çš„é•¿åº¦
    'max_gen_seq_len': 40,  # ç”Ÿæˆç­”æ¡ˆæœ€å¤§é•¿åº¦
    'random_prompts': [  # éšæœºpromptæ± 
        'ä»Šå¤©æˆ‘å»äº†',
        'è¿™éƒ¨ç”µå½±å¾ˆ',
        'åˆšæ”¶åˆ°è´§ï¼Œæ„Ÿè§‰',
        'è¿™éƒ¨ç”µå½±å¾ˆ',
        'è¯´å®è¯ï¼ŒçœŸçš„å¾ˆ',
        'è¿™æ¬¡è´­ç‰©æ€»çš„æ¥è¯´ä½“éªŒå¾ˆ'
    ]
}

######################## ä¼šè¯ç¼“å­˜åˆå§‹åŒ– ###########################
# if 'model_config' not in st.session_state:
# st.session_state['model_config'] = MODEL_CONFIG

if 'model' not in st.session_state:
    # model_name = st.session_state['model_config']['model_name']
    # st.session_state['model'] = T5Tokenizer.from_pretrained(model_name)
    st.session_state['model'] = T5ForConditionalGeneration.from_pretrained("model/language_model/ChatYuan-large-v1")
    st.session_state['model'].to(device)

if 'tokenizer' not in st.session_state:
    # model_name = st.session_state['model_config']['model_name']
    st.session_state['tokenizer'] = T5Tokenizer.from_pretrained("model/language_model/ChatYuan-large-v1")

# if 'generator' not in st.session_state:
#     st.session_state['generator'] = T5ForConditionalGeneration(
#         st.session_state['model'],
#         st.session_state['tokenizer'],
#         device=MODEL_CONFIG['device']
#     )

if 'current_results' not in st.session_state:
    st.session_state['current_results'] = [''] * MODEL_CONFIG['rank_list_len']

if "results_combinations" not in st.session_state:
    st.session_state['results_combinations'] = ["åˆå§‹åŒ–ç»“æœ"]

if 'current_prompt' not in st.session_state:
    st.session_state['current_prompt'] = 'æˆ‘è¢«é‚»å±…å®¶çš„ç‹—å’¬äº†æ€ä¹ˆåŠï¼Ÿ'


######################### å‡½æ•°å®šä¹‰åŒº ##############################
# åŸºç¡€çš„é¢„å¤„ç†å’Œåå¤„ç†
def preprocess(text):
    text = text.replace("\n", "\\n").replace("\t", "\\t")
    return text


def postprocess(text):
    return text.replace("\\n", "\n").replace("\\t", "\t")


def answer(text, sample=True, top_p=1, temperature=0.7):
    """sampleï¼šæ˜¯å¦æŠ½æ ·ã€‚ç”Ÿæˆä»»åŠ¡ï¼Œå¯ä»¥è®¾ç½®ä¸ºTrue;
    top_pï¼š0-1ä¹‹é—´ï¼Œç”Ÿæˆçš„å†…å®¹è¶Šå¤šæ ·"""
    text = preprocess(text)
    encoding = st.session_state['tokenizer'](text=[text], truncation=True, padding=True, max_length=768,
                                             return_tensors="pt").to(device)
    if not sample:
        out = st.session_state['model'].generate(**encoding, return_dict_in_generate=True, output_scores=False,
                                                 max_new_tokens=512,
                                                 num_beams=1, length_penalty=0.6)
    else:
        out = st.session_state['model'].generate(**encoding, return_dict_in_generate=True, output_scores=False,
                                                 max_new_tokens=512,
                                                 do_sample=True, top_p=top_p, temperature=temperature,
                                                 no_repeat_ngram_size=3)
    out_text = st.session_state['tokenizer'].batch_decode(out["sequences"], skip_special_tokens=True)
    # st.session_state['current_results'] = postprocess(out_text[0])
    return postprocess(out_text[0])


def generate_text():
    """
    æ¨¡å‹ç”Ÿæˆæ–‡å­—ã€‚
    """
    current_results = []
    for _ in range(MODEL_CONFIG['rank_list_len']):
        res = answer(text=st.session_state['current_prompt'])
        current_results.append(res)
    st.session_state['current_results'] = current_results


def data_show(idx):
    one_res = st.session_state['results_combinations'][idx]

    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"<font color=#008000> {one_res[0]} </font>", unsafe_allow_html=True)
    with col2:
        st.markdown(f"<font color=blue> {one_res[1]} </font>", unsafe_allow_html=True)

    with col1:
        # st.radio(label="ä¸Šä¸€å¥")
        selected_answers = st.radio(label="", options=["å·¦", "å³"])
    with col2:
        st.write("")
        st.write("")
        st.write("")
        next_ = st.button("next")

    return selected_answers, next_


######################### é¡µé¢å®šä¹‰åŒºï¼ˆä¾§è¾¹æ ï¼‰ ########################

st.sidebar.title('Rank Labeler Tool')

label_tab, dataset_tab = st.tabs(['Label', 'Dataset'])

with label_tab:
    random_button = st.button('éšæœº prompt',
                              help='ä»promptæ± ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªpromptï¼Œå¯é€šè¿‡ä¿®æ”¹æºç ä¸­ MODEL_CONFIG["random_prompts"] å‚æ•°æ¥è‡ªå®šä¹‰promptæ± ã€‚')
    if random_button:
        prompt_text = random.choice(MODEL_CONFIG['random_prompts'])
    else:
        prompt_text = st.session_state['current_prompt']

    query_txt = st.text_input('prompt: ', prompt_text)
    if query_txt != st.session_state['current_prompt']:
        st.session_state['current_prompt'] = query_txt
        generate_text()
        st.session_state['results_combinations'] = list(combinations(st.session_state["current_results"], 2))
        # st.write(st.session_state['current_results'])

    with st.expander('ğŸ’¡ åˆ¤æ–­å·¦è¾¹çš„ç»“æœæ˜¯å¦æ¯”å³è¾¹çš„ç»“æœå¥½', expanded=True):
        if st.session_state['current_results'][0] == '':
            generate_text()
            st.session_state['results_combinations'] = list(combinations(st.session_state["current_results"], 2))

        i = 0
        selected_answers, next_ = data_show(i)
        i = i + 1
        while next_ and i < len(st.session_state['results_combinations']) - 1:
            data_show(i)
        # columns = st.columns([1] * MODEL_CONFIG['rank_list_len'])
        # columns = 3
        # st.write("åˆ¤æ–­å·¦è¾¹çš„ç»“æœæ˜¯å¦æ¯”å³è¾¹çš„ç»“æœå¥½")

        # rank_results = [-1] * MODEL_CONFIG['rank_list_len']
        # rank_choices = [-1] + [i + 1 for i in range(MODEL_CONFIG['rank_list_len'])]
        # for i, c in enumerate(columns):
        #     with c:
        #         choice = st.selectbox(f'å¥å­{i+1}æ’å', rank_choices, help='ä¸ºå½“å‰å¥å­é€‰æ‹©æ’åï¼Œæ’åè¶Šå°ï¼Œå¾—åˆ†è¶Šé«˜ã€‚ï¼ˆ-1ä»£è¡¨å½“å‰å¥å­æš‚æœªè®¾ç½®æ’åï¼‰')
        #         if choice != -1 and choice in rank_results:
        #             st.info(f'å½“å‰æ’å[{choice}]å·²ç»è¢«å¥å­[{rank_results.index(choice)+1}]å ç”¨ï¼Œè¯·å…ˆå°†å ç”¨æ’åçš„å¥å­ç½®ä¸º-1å†ä¸ºå½“å‰å¥å­åˆ†é…è¯¥æ’åã€‚')
        #         else:
        #             rank_results[i] = choice
        #         color = RANK_COLOR[i] if i < len(RANK_COLOR) else 'white'
        #         # st.write(color)
        #         st.markdown(f":{color}[{st.session_state['current_results'][i]}]")

with dataset_tab:
    st.write('Dataset')
